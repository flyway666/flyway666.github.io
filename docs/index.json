[{"categories":["技術--PostgreSQL"],"content":"pg使用触发器记录ddl postgreSQL开放事件触发器，可以实现DDL回收站、DDL防火墙、DDL增量订阅同步等功能，灵活使用事件触发器可以减少维护成本，保护数据安全。 RDS PostgreSQL开放事件触发器，可以实现DDL回收站、DDL防火墙、DDL增量订阅同步等功能，灵活使用事件触发器可以减少维护成本，保护数据安全。 前提条件 实例版本为PostgreSQL 10、11、12云盘版。 背景信息 如果您对数据库安全有非常高的要求，可以基于事件触发器创建DDL回收站规则、DDL防火墙规则，在多个维度保护数据安全： 事前防御：防止drop table、drop index、drop database等删库删表危险操作。 事后回档：在发生意外删表后，可以从回收站找回。 原理是使用pg_get_ddl_command和pg_get_ddl_drop这两个事件触发器收集并存入DDL语句到表dts_audit.dts_tb_ddl_command中，其具体实现在函数pg_func_ddl_command()中。其中dts_audit.dts_tb_ddl_command表结构如下： Column | Type | Collation | Nullable | Default | Storage | Stats target | Description —————–+—————————–+———–+———-+——————–+———-+————–+————- event | text | | | | extended | | tag | text | | | | extended | | Command tag classid | oid | | | | plain | | OID of catalog the object belonged in objid | oid | | | | plain | | OID the object had within the catalog objsubid | integer | | | | plain | | Object sub-id (e.g. attribute number for columns) object_type | text | | | | extended | | Type of the object schema_name | text | | | | extended | | Name of the schema the object belonged in, if any; otherwise NULL. No quoting is applied. object_identity | text | | | | extended | | Text rendering of the object identity, schema-qualified. is_extension | boolean | | | | plain | | True if the command is part of an extension script query | text | | | | extended | | sql text username | text | | | CURRENT_USER | extended | | datname | text | | | current_database() | extended | | client_addr | inet | | | inet_client_addr() | main | | crt_time | timestamp without time zone | | | now() | plain | | 创建语句如下： CREATE SCHEMA IF NOT EXISTS dts_audit; CREATE TABLE IF NOT EXISTS dts_audit.dts_tb_ddl_command ( event text, tag text, classid oid, objid oid, objsubid int, object_type text, schema_name text, object_identity text, is_extension bool, query text, username text default current_user, datname text default current_database(), client_addr inet default inet_client_addr(), crt_time timestamp default now() );\r下文将以示例的方式介绍如何实现DDL回收站、DDL防火墙、DDL增量订阅及同步等功能，您可以根据业务情况修改相关代码。 DDL回收站 执行如下命令创建表、函数和相关触发器。 RDS PostgreSQL开放事件触发器，可以实现DDL回收站、DDL防火墙、DDL增量订阅同步等功能，灵活使用事件触发器可以减少维护成本，保护数据安全。 前提条件 实例版本为PostgreSQL 10、11、12云盘版。 背景信息 如果您对数据库安全有非常高的要求，可以基于事件触发器创建DDL回收站规则、DDL防火墙规则，在多个维度保护数据安全： 事前防御：防止drop table、drop index、drop database等删库删表危险操作。 事后回档：在发生意外删表后，可以从回收站找回。 原理是使用pg_get_ddl_command和pg_get_ddl_drop这两个事件触发器收集并存入DDL语句到表dts_audit.dts_tb_ddl_command中，其具体实现在函数pg_func_ddl_command()中。其中dts_audit.dts_tb_ddl_command表结构如下： Column | Type | Collation | Nullable | Default | Storage | Stats target | Description -----------------+-----------------------------+-----------+----------+--------------------+----------+--------------+------------- event | text | | | | extended | | tag | text | | | | extended | | Command tag classid | oid | | | | plain | | OID of catalog the object belonged in objid | oid | | | | plain | | OID the object had within the catalog objsubid | integer | | | | plain | | Object sub-id (e.g. attribute number for columns) object_type | text | | | | extended | | Type of the object schema_name | text | | | | extended | | Name of the schema the object belonged in, if any; otherwise NULL. No quoting is applied. object_identity | text | | | | extended | | Text rendering of the object identity, schema-qualified. is_extension | boolean | | | | plain | | True if the command is part of an extension script query | text | | | | extended | | sql text username | text | | | CURRENT_USER | extended | | datname | text | | | current_database() | extended | | client_addr | inet | | | inet_client_addr() | main | | crt_time | timestamp without time zone | | | now() | plain | | 创建语句如下： CREATE SCHEMA IF NOT EXISTS dts_audit; CREATE TABLE IF NOT EXISTS dts_audit.dts_tb_ddl_command ( event text, tag text, classid oid, objid oid, objsubid int, object_type text, schema_name text, object_identity text, is_extension bool, query text, username text default current_user, datname text default current_database(), c","date":"2026-02-08","objectID":"/2026020805/:0:0","tags":["PostgreSQL","資料庫"],"title":"pg使用触发器记录ddl","uri":"/2026020805/"},{"categories":["技術--PostgreSQL"],"content":"备份恢复脚本 备份脚本win @echo off echo execute pg_dump set /p dbname=please input database name: echo dump database is %dbname% set /p ipaddress=please input database IP: echo dump databaseIP is %ipaddress% D:\\ProgramFiles\\PostgreSQL\\pgAdmin4\\v6\\runtime\\pg_dump.exe --file \"D:\\\\\\\\%dbname%\" --host \"%ipaddress%\" --port \"5432\" --username \"datalink\" --exclude-schema=public --verbose --role \"datalink\" --format=c --blobs --encoding \"UTF8\" %dbname% echo done! pause\r备份所有ddl @echo off echo execute pg_dump set /p dbname=please input database name: echo dump database is %dbname% set /p ipaddress=please input database IP: echo dump databaseIP is %ipaddress% D:\\ProgramFiles\\PostgreSQL\\pgAdmin4\\v6\\runtime\\pg_dump.exe --file \"D:\\\\\\\\%dbname%\" --host \"%ipaddress%\" --port \"5432\" --username \"datalink\" --exclude-schema=public --verbose --role \"datalink\" --format=p --schema-only --blobs --encoding \"UTF8\" %dbname% echo done! pause\r恢复脚本win @echo off echo execute pg_dump set /p dbname=please input database name: echo dump database is %dbname% set /p ipaddress=please input database IP: echo dump databaseIP is %ipaddress% D:\\ProgramFiles\\PostgreSQL\\pgAdmin4\\v6\\runtime\\pg_restore.exe --host \"%ipaddress%\" --port \"5432\" --username \"datalink\" --role \"datalink\" --dbname \"%dbname%\" --exclude-schema=public --verbose \"D:\\\\%dbname%\" echo done! pause\r","date":"2026-02-08","objectID":"/2026020804/:0:0","tags":["PostgreSQL","資料庫"],"title":"备份恢复脚本","uri":"/2026020804/"},{"categories":["技術--PostgreSQL"],"content":"统计表膨胀率 WITH bloat AS ( WITH t1 AS ( SELECT schemaname, tablename, ( 23 + CEIL ( COUNT ( * ) \u003e\u003e 3 ) ) :: BIGINT nullheader, MAX ( null_frac ) nullfrac, CEIL ( SUM ( ( 1 - null_frac ) * avg_width ) ) :: BIGINT datawidth FROM pg_stats --where schemaname='form' GROUP BY schemaname, tablename ), t2 AS ( SELECT schemaname, tablename, ( datawidth + 8 - ( CASE WHEN datawidth % 8 = 0 THEN 8 ELSE datawidth % 8 END ) ) -- avg data len + ( 1 - nullfrac ) * 24 + nullfrac * ( nullheader + 8 - ( CASE WHEN nullheader % 8 = 0 THEN 8 ELSE nullheader % 8 END ) ) avgtuplelen FROM t1 ) SELECT C .oid, avgtuplelen FROM t2 T, pg_class C, pg_namespace n WHERE T.schemaname = n.nspname AND C.relname = T.tablename AND C.relnamespace = n.oid AND relpages \u003e 100 and c.relname in ( select relname from ( select relname , reltuples::numeric as 记录数 from pg_class where relkind = 'r' )t order by 记录数 desc limit 50) ), parti AS ( SELECT parti.inhparent, parti.inhrelid, stat.n_dead_tup, c.relpages, c.reltuples FROM ( SELECT inhparent, inhrelid FROM pg_inherits inh UNION ALL ( SELECT b.inhparent AS grandpa, A.inhrelid me FROM pg_inherits A INNER JOIN pg_inherits b ON A.inhparent = b.inhrelid ) ) AS parti inner join pg_class c on parti.inhrelid = c.oid LEFT JOIN pg_stat_user_tables stat ON parti.inhrelid = stat.relid where c.relname in ( select relname from ( select relname , reltuples::numeric as 记录数 from pg_class where relkind = 'r' )t order by 记录数 desc limit 50) ) SELECT n.nspname \"tableSchema\", C.relname \"tableName\", 'vacuum full '||C.relname||';' \"sql\", round(SUM ( pg_total_relation_size ( COALESCE ( parti1.inhrelid, C.oid ) )+0.0 )/1024/1024/1024,2) AS \"表大小 GB\", --表及其子分区、索引大小，包含索引 round( SUM ( pg_total_relation_size ( COALESCE ( parti1.inhrelid, C.oid ) ) ) / ( SELECT SUM ( pg_database_size ( datname ) ) AS dbsize FROM pg_database ), 4 ) AS \"占数据文件比例%\",-- 表占数据文件比例 to_char(COALESCE ( MAX ( c.reltuples ), 0 ) + COALESCE ( SUM ( COALESCE ( parti1.reltuples, 0 ) ), 0 ),'9999999999') AS \"元组(记录行数)\", CASE WHEN (coalesce(max( bloat.avgtuplelen), 0) = 0 and coalesce(avg( parti1.avgtuplelen), 0) = 0) or MAX ( COALESCE (c.relpages , 0 ) ) + SUM ( COALESCE ( parti1.relpages, 0 )) = 0 THEN 0 ELSE round((1 - CEIL ( (MAX ( COALESCE ( c.reltuples, 0 )) + SUM ( COALESCE ( parti1.reltuples, 0 ))) * (case when max( parti1.avgtuplelen) is not null then AVG( parti1.avgtuplelen) else max ( COALESCE ( bloat.avgtuplelen, 0 ) ) end ) / 8168) / ( MAX ( COALESCE (c.relpages , 0 ) ) + SUM ( COALESCE ( parti1.relpages, 0 )) ))::NUMERIC, 2)*100 END AS \"表膨胀率%\", COALESCE ( MAX ( stat.n_dead_tup ), 0 ) + COALESCE ( SUM ( COALESCE ( parti1.n_dead_tup, 0 ) ), 0 ) AS \"死元组(行)\" --表内死数据行 FROM pg_class C INNER JOIN pg_namespace n ON C.relnamespace = n.oid LEFT JOIN pg_stat_user_tables stat ON C.oid = stat.relid LEFT JOIN (select p.*, b.* from parti p left join bloat as b ON p.inhrelid = b.oid) as parti1 on c.oid = parti1.inhparent LEFT JOIN bloat ON C.oid = bloat.oid WHERE n.nspname NOT IN ( 'pg_catalog', 'information_schema' ) AND n.nspname !~ '^pg_toast' AND C.relkind IN ( 'r', 'p' ) AND C.oid NOT IN ( SELECT inhrelid FROM pg_inherits ) and c.relname in ( select relname from ( select relname , reltuples::numeric as 记录数, 'truncate table '||relname||' ;' from pg_class where relkind = 'r' )t order by 记录数 desc limit 50) GROUP BY C.relname, n.nspname ORDER BY -- \"表大小 GB\" DESC \"表膨胀率%\" DESC limit 100 ","date":"2026-02-08","objectID":"/2026020803/:0:0","tags":["PostgreSQL","資料庫"],"title":"统计表膨胀率","uri":"/2026020803/"},{"categories":["技術--PostgreSQL"],"content":"自己编写的备份脚本 #!/bin/bash #备份功能的话 记得 在 gkit 推送流水线的时候 要做逻辑分区 ，不要和当前的数据库用一个盘 # 备份文件目录 BKUP_DATADIR=/opt/srv/smartcare/hypergis/pg-data # 日志文件目录 log_dir=/opt/srv/smartcare/hypergis/scripts #备份日志 LOG_BK_FILE=${log_dir}/backupCtl_bk.log LOG_FILE=${log_dir}/backupCtl.log # 日志10M后要转储 MAX_LOGFILE_SIZE=10485760 # 写日志 function logMsg() { echo \"$1\" \u003e\u003e ${LOG_FILE} } # 清理日志文件,保留一个历史备份日志 function clearLogFile() { logFileSize=$(ls -l ${LOG_FILE} | awk '{print $5}') if [[ ${logFileSize} -gt ${MAX_LOGFILE_SIZE} ]];then logMsg \"`date '+%Y-%m-%d %H %M %S'`:log file is greater than ${MAX_LOGFILE_SIZE},backup it now\" rm -rf ${LOG_BK_FILE} mv ${LOG_FILE} ${LOG_BK_FILE} fi } # 备份数据 function backupData() { logMsg \"`date '+%Y-%m-%d %H %M %S'`:begin backup db\" local filename=\"datalinkbackup_`date '+%Y-%m-%d'`\" local backfile=${BKUP_DATADIR}'/'${filename} docker exec $(docker ps |grep gis-postgresql:11.13|awk '{print $1}') sh -c 'source /opt/gis-postgresql/config/postgres_profile.sh \u0026\u0026 pg_dump --port 1523 --username datalink --no-password -d datalink --host 127.0.0.1 --format=c --blobs --encoding \"UTF8\" --verbose --file '${backfile}' \u0026\u003e\u003e '${LOG_FILE}'' logMsg \"`date '+%Y-%m-%d %H %M %S'`:end backup db\" } #删除超过3天的备份文件 function clearFile() { filePath=$1 fileFlag=$2 logMsg \"`date '+%Y-%m-%d %H %M %S'`:begin clearFile\" cd ${filePath} local fileNum=$(ls -l |grep ${fileFlag}|wc -l) #Backup files are retained for 7 days. if [ ${fileNum} -ge 3 ];then local deleteFile=$(ls -l |grep ${fileFlag} | awk -F ' ' '{print $9}'|awk 'NR==1{print}') local time=$(stat -c %Y ${deleteFile}) for file in $(ls -l |grep ${fileFlag} | awk -F ' ' '{print $9}') do local fileCreatDate=$(stat -c %Y ${file}) if [[ ${fileCreatDate} \u003c ${time} ]];then deleteFile=${file} fi done if [ -n \"${deleteFile}\" ];then #clear old data rm -rf ${deleteFile} fi fi logMsg \"`date '+%Y-%m-%d %H %M %S'`:end clearFile\" } #backup function backup_main() { #使用walsender进程判断是否主节点 primary_flag=`docker exec $(docker ps |grep gis-postgresql:11.13|awk '{print $1}') sh -c 'source /opt/gis-postgresql/config/postgres_profile.sh \u0026\u0026 pg_controldata -D /opt/srv/smartcare/hypergis/pg-data | grep \"in production\" |wc -l'` if [[ \"${primary_flag}\" -eq 1 ]] then #清理备份日志 clearLogFile logMsg \"`date '+%Y-%m-%d %H %M %S'`:this is primary db\" #是主节点就备份数据 backupData ${BKUP_DATADIR} #删除超过3天的备份文件 clearFile ${BKUP_DATADIR} \"datalinkbackup\" else echo \"this is standby db don backup db\" fi } backup_main\r","date":"2026-02-08","objectID":"/2026020802/:0:1","tags":["PostgreSQL","資料庫"],"title":"postggresq备份脚本","uri":"/2026020802/"},{"categories":["技術--PostgreSQL"],"content":"#PostgreSQL中有两类锁：表级锁和行级锁。当要查询、插入、更新、删除表中数据时，首先要获得表级锁，然后获得行级锁。 下面对PostgreSQL数据库锁机制的理解，大部分来自与《PostgreSQL修炼之道 从小工到专家》-唐成书中，以及网络上的博客的总结。通过实际测试发现，还是存在一些不合理的点，后面实际的案列中，会有一些说明。 1.表级锁模式 锁模式 解释 Access Share 只与Access Exclusive锁模式冲突。 Access Share 查询命令（Select command）将会在它查询的表上获取Access Shared锁，一般地，任何一个对表上的只读查询操作都将获取这种类型锁。 Row Share 与Exclusive和Access Exclusive锁模式冲突。 Row Share Select for update和Select for share命令将获得这种类型锁，并且所有被引用但没有for update 的表上会加上Access Shared锁。 Row Exclusive 与Share，Shared Row Exclusive，Exclusive，Access Exclusive模式冲突。 Row Exclusive Update/Delete/Insert命令会在目标表上获得这种类型的锁，并且在其它被引用的表上加上Access Share锁，一般地，更改表数据的命令都将在这张表上获得Row Exclusive锁。 Share Update Exclusive Share Update Exclusive，Share，Share Row Exclusive，Exclusive，Access exclusive模式冲突，这种模式保护一张表不被并发的模式更改和Vacuum。 Vacuum(without full)，Analyze 和 Create index concur-ently命令会获得这种类型锁。 Share 与Row Exclusive，Shared Update Exclusive，Share Row Exclusive，Exclusive，Access exclusive锁模式冲突，这种模式保护一张表数据不被并发的更改。 Share Create index命令会获得这种锁模式。 Share Row Exclusive 与Row Exclusive，Share Update Exclusive，Shared，Shared Row Exclusive，Exclusive，Access Exclusive锁模式冲突。 Share Row Exclusive 任何PostgreSQL命令不会自动获得这种类型的锁。 Exclusive 与ROW Share , Row Exclusive, Share Update Exclusive, Share , Share Row Exclusive, Exclusive, Access Exclusive模式冲突，这种锁模式仅能与Access Share 模式并发，换句话说，只有读操作可以和持有Exclusive锁的事务并行。 Exclusive 任何PostgreSQL命令不会自动获得这种类型的锁。 Access Exclusive 与所有模式锁冲突(Access Share，Row Share，Row Exclusive，Share Update Exclusive，Share , Share Row Exclusive，Exclusive，Access Exclusive)，这种模式保证了当前只有一个人访问这张表；ALTER TABLE，DROP TABLE，TRUNCATE，REINDEX，CLUSTER，VACUUM FULL 命令会获得这种类型锁，在Lock table 命令中，如果没有申明其它模式，它也是默认模式。 2.表级锁的冲突矩阵 请求的锁模式 请求的锁模式 “Access Share” “Row Share” “Row Exclusive” “Share Update Exclusive” Share “Share Row Exclusive” Exclusive “Access Exclusive” Access Share Y Y Y Y Y Y Y N Row Share Y Y Y Y Y Y N N Row Exclusive Y Y Y Y N N N N Share Update Exclusive Y Y Y N N N N N Share Y Y Y N N N N N Share Row Exclusive Y Y N N N N N N Exclusive Y N N N N N N N Access Exclusive N N N N N N N N 表中“N”表示这两种表冲突，也就是不同的进程不能同时持有这两种锁。 最普通的是Share和Exclusive这两种锁，它们分别是读、写锁的意思。加了Share锁，即读锁，表的内容就不被修改了；可以为多个事务加上此锁，只要任意一个事务不释放这个读锁，则其他事务就不能修改这个表。加上了Exclusive，相当于加了写锁，这时别的进程不能写也不能读这条数据。但后来数据库又加上了多版本的功能。修改一条语句的同时，允许了读数据，为了处理这种情况，又增加了两种锁Access Share和Access Excusive，锁中的关键字 Access 是与多版本相关的有了该功能。其实，有了该功能后，如果修改一行数据，实际并没有改原先那行数据，而是复制了一个新行，修改都在新行上，事务不提交，其他人是看不到修改的这条数据的。由于旧行数据没有变化，在修改过程中，读数据的人仍然可以读到旧的数据。 表级锁加锁对象是表，这使得加锁范围太大，导致并发并不高，于是人们提出了行级锁的概念，但行级锁与表级锁之间会产生冲突，这时需要一种机制来描述行级锁与表级锁之间的关系，有了意向锁的概念，这时又加了两种锁，即意向共享锁（Row Share） 和意向排他锁（Row Exclusive），由于意向锁之间不会产生冲突，因为他们是“有意”做，还没真做；而且意向排它锁相互之间也不会产生冲突，于是又需要更严格一些的锁，这样就产生了Share Update Exclusive，Share Row Exclusive可以看成Share与Row Exclusive，PostgreSQL不会自动请求这个锁模式，也就是PostgreSQL内部目前没有使用这种锁。 这里稍微补充一下多版本并发控制原理。 多版本并发控制原理： 大家熟知的读与写锁是不能并发的，所以有人想到一种新的能够让读写并发的方法，称这种方法为MVCC。MVCC的方法是写数据时，旧版本的数据并不删除，并发的读操作还能读到旧版本的数据。 实现MVCC的两种方法： 写新数据时，把旧数据移到一个单独的地方，如回滚段中，其他读数据时，从回滚段中把旧版本数据读出来。 写新数据时，旧版本的数据不删除，而是把新数据插入。 PostgreSQL数据库使用的正是第二种方法，而oracle与MySQL中的innodb引擎用的是第一种方法。 PostgreSQL实现该功能，需要在每张表上添加四个系统字段tmin、tmax、cmin、cmax，通过这四个字段可以区分并发时，记录不同数据的版本，和事务标识，当删除时，只会标记记录，而不会从数据块中删除，空间也没有立即释放。 PostgreSQL通过运行vaccum进程来进行回收之前的存储空间，默认PostgreSQL中的autovacuum是打开的，当一表更新达到一定数量时，autovacuum会自动回收空间。 3.表级锁类型对应的数据库操作 锁类型 对应的数据库操作 Access Share select Row Share select for update, select for share Row Exclusive update，delete，insert Share Update Exclusive vacuum(without full)，analyze，create index concurrently Share create index Share Row Exclusive 任何Postgresql命令不会自动获得这种类型的锁 Exclusive 任何Postgresql命令不会自动获得这种类型的锁 Access Exclusive alter table，drop table，truncate，reindex，cluster，vacuum full 4.行级锁模式 行级锁模式只有两种，分别是共享锁和排他锁，或者说是读锁或写锁。由于多版本的实现，实际读取行数据时，并不会在行上执行任何锁。 特定行上的行级锁是在行被更新的时候自动请求的（或者被删除时或标记为更新）。 锁一直保持到事务提交或者回滚。行级锁不影响对数据的查询；它们只阻塞对同一行的写入。 要在不修改某行的前提下请求在该行的行级锁，用 SELECT FOR UPDATE 选取该行。请注意一旦我们请求了特定的行级锁，那么该事务就可以多次对该行进行更新而不用担心冲突。 《PostgreSQL修炼之道 从小工到专家》-唐成书中强调的是，行级锁只有共享锁与排他锁，也就是读锁、写锁，但是实际测试中有发现一些tuple类型的多版本控制的写锁。 5.页级锁 除了表级别的和行级别的锁以外， 页面级别的共享/排他销也用于控制对共享缓冲池中表页面的读/写访问。这些锁在抓取或者更新","date":"2026-02-08","objectID":"/2026020801/:0:0","tags":["PostgreSQL","資料庫"],"title":"PostgreSQL锁机制","uri":"/2026020801/"},{"categories":["技術--PostgreSQL"],"content":"PG_DBA_运维手册 ","date":"2026-02-08","objectID":"/pg_dba/:0:0","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"查看database的owner select datname, usename as owner from pg_database left join pg_user on usesysid = datdba;\r","date":"2026-02-08","objectID":"/pg_dba/:0:1","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"查看可见SCHEMA select * from information_schema.schemata;\r","date":"2026-02-08","objectID":"/pg_dba/:0:2","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"查看表膨胀（对所有表进行膨胀率排序），取前10个 SELECT schemaname||'.'||relname as table_name, pg_size_pretty(pg_relation_size(schemaname||'.'||relname)) as table_size, n_dead_tup, n_live_tup, round(n_dead_tup * 100 / (n_live_tup + n_dead_tup),2) AS dead_tup_ratio FROM pg_stat_all_tables WHERE n_dead_tup \u003e= 1000 and schemaname in ('base','workspace','permission','process','form','pipeline') ORDER BY dead_tup_ratio DESC LIMIT 10;\r","date":"2026-02-08","objectID":"/pg_dba/:0:3","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"表膨胀处理 VACUUM (VERBOSE, ANALYZE) 表明，不锁表，不影响业务使用 VACUUM ( FULL,VERBOSE ) 表名称 ，注意会锁表，连查询都不可以\r","date":"2026-02-08","objectID":"/pg_dba/:0:4","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"设置序列catche 1 (无缓存,每个进程取值就连续了) select 'alter sequence '|| sequence_name|| ' cache 1 ;' from information_schema.sequences where sequence_schema != 'public'\r查看性能sql ","date":"2026-02-08","objectID":"/pg_dba/:0:5","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"查看正在执行的sql,长事务（top sql） select datname, usename, client_addr, application_name, state, backend_start, xact_start, xact_stay, query_start, query_stay, now() - query_start AS Duration, replace(query, chr(10), ' ') as query from (select pgsa.datname as datname, pgsa.usename as usename, pgsa.client_addr client_addr, pgsa.application_name as application_name, pgsa.state as state, pgsa.backend_start as backend_start, pgsa.xact_start as xact_start, extract(epoch from (now() - pgsa.xact_start)) as xact_stay, pgsa.query_start as query_start, extract(epoch from (now() - pgsa.query_start)) as query_stay, pgsa.query as query from pg_stat_activity as pgsa where pgsa.state != 'idle' and pgsa.state != 'idle in transaction' and pgsa.state != 'idle in transaction (aborted)' and usename='datalink' --and (now() - query_start) \u003e interval '10 seconds' ) idleconnections order by query_stay desc limit 5;\r","date":"2026-02-08","objectID":"/pg_dba/:0:6","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"查看之前执行的sql SELECT procpid, start, now() - start AS lap, current_query FROM (SELECT backendid, pg_stat_get_backend_pid(S.backendid) AS procpid, pg_stat_get_backend_activity_start(S.backendid) AS start, pg_stat_get_backend_activity(S.backendid) AS current_query FROM (SELECT pg_stat_get_backend_idset() AS backendid) AS S ) AS S WHERE current_query \u003c\u003e '\u003cIDLE\u003e' ORDER BY lap DESC;\rprocpid：进程id , 强制结束 SELECT pg_cancel_backend(进程id) –取消后台操作; SELECT pg_terminate_backend(PID) –中断session; start：进程开始时间 lap：经过时间 current_query：执行中的sql 慢SQL、TOP SQL优化示例 begin; set local lock_timeout='1s'; set local statement_timeout=0; explain (analyze,verbose,timing,costs,buffers,timing) SQL; -- SQL代替为要分析的SQL rollback; ","date":"2026-02-08","objectID":"/pg_dba/:0:7","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"空闲连接 select * from pg_stat_activity where usename='datalink' and state='idle' order by query_start\r","date":"2026-02-08","objectID":"/pg_dba/:0:8","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"表大小前一百个（包含索引） WITH bloat AS ( WITH t1 AS ( SELECT schemaname, tablename, ( 23 + CEIL ( COUNT ( * ) \u003e\u003e 3 ) ) :: BIGINT nullheader, MAX ( null_frac ) nullfrac, CEIL ( SUM ( ( 1 - null_frac ) * avg_width ) ) :: BIGINT datawidth FROM pg_stats GROUP BY schemaname, tablename ), t2 AS ( SELECT schemaname, tablename, ( datawidth + 8 - ( CASE WHEN datawidth % 8 = 0 THEN 8 ELSE datawidth % 8 END ) ) -- avg data len + ( 1 - nullfrac ) * 24 + nullfrac * ( nullheader + 8 - ( CASE WHEN nullheader % 8 = 0 THEN 8 ELSE nullheader % 8 END ) ) avgtuplelen FROM t1 ) SELECT C .oid, avgtuplelen FROM t2 T, pg_class C, pg_namespace n WHERE T.schemaname = n.nspname AND C.relname = T.tablename AND C.relnamespace = n.oid AND relpages \u003e 100 ), parti AS ( SELECT parti.inhparent, parti.inhrelid, stat.n_dead_tup, c.relpages, c.reltuples FROM ( SELECT inhparent, inhrelid FROM pg_inherits inh UNION ALL ( SELECT b.inhparent AS grandpa, A.inhrelid me FROM pg_inherits A INNER JOIN pg_inherits b ON A.inhparent = b.inhrelid ) ) AS parti inner join pg_class c on parti.inhrelid = c.oid LEFT JOIN pg_stat_user_tables stat ON parti.inhrelid = stat.relid ) SELECT n.nspname \"tableSchema\", C.relname \"tableName\", SUM ( pg_total_relation_size ( COALESCE ( parti1.inhrelid, C.oid ) ) ) AS \"tableSize\", --表及其子分区、索引大小，包含索引 round( SUM ( pg_total_relation_size ( COALESCE ( parti1.inhrelid, C.oid ) ) ) / ( SELECT SUM ( pg_database_size ( datname ) ) AS dbsize FROM pg_database ), 4 ) AS tblpercent,-- 表占数据文件比例 COALESCE ( MAX ( c.reltuples ), 0 ) + COALESCE ( SUM ( COALESCE ( parti1.reltuples, 0 ) ), 0 ) AS \"tableRows\", CASE WHEN (coalesce(max( bloat.avgtuplelen), 0) = 0 and coalesce(avg( parti1.avgtuplelen), 0) = 0) or MAX ( COALESCE (c.relpages , 0 ) ) + SUM ( COALESCE ( parti1.relpages, 0 )) = 0 THEN 0 ELSE round((1 - CEIL ( (MAX ( COALESCE ( c.reltuples, 0 )) + SUM ( COALESCE ( parti1.reltuples, 0 ))) * (case when max( parti1.avgtuplelen) is not null then AVG( parti1.avgtuplelen) else max ( COALESCE ( bloat.avgtuplelen, 0 ) ) end ) / 8168) / ( MAX ( COALESCE (c.relpages , 0 ) ) + SUM ( COALESCE ( parti1.relpages, 0 )) ))::NUMERIC, 2) END AS bloat_pct, COALESCE ( MAX ( stat.n_dead_tup ), 0 ) + COALESCE ( SUM ( COALESCE ( parti1.n_dead_tup, 0 ) ), 0 ) AS \"deadTup\" --表内死数据行 FROM pg_class C INNER JOIN pg_namespace n ON C.relnamespace = n.oid LEFT JOIN pg_stat_user_tables stat ON C.oid = stat.relid LEFT JOIN (select p.*, b.* from parti p left join bloat as b ON p.inhrelid = b.oid) as parti1 on c.oid = parti1.inhparent LEFT JOIN bloat ON C.oid = bloat.oid WHERE n.nspname NOT IN ( 'pg_catalog', 'information_schema' ) AND n.nspname !~ '^pg_toast' AND C.relkind IN ( 'r', 'p' ) AND C.oid NOT IN ( SELECT inhrelid FROM pg_inherits ) GROUP BY C.relname, n.nspname ORDER BY \"tableSize\" DESC limit 100\r–查看表记录数 select relname as 表名, reltuples as 记录数 from pg_class where relkind = 'r' and relnamespace = (select oid from pg_namespace where nspname='base') order by 记录数 desc;\r","date":"2026-02-08","objectID":"/pg_dba/:0:9","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"},{"categories":["技術--PostgreSQL"],"content":"查看schema大小 SELECT \"tableSchema\" as \"column\", --schemanamen sum(\"tableSize\") / 1024 / 1024 \"schemaSize\" --schema大小 FROM ( WITH bloat AS ( WITH t1 AS ( SELECT schemaname, tablename, ( 23 + CEIL ( COUNT ( * ) \u003e\u003e 3 ) ) :: BIGINT nullheader, MAX ( null_frac ) nullfrac, CEIL ( SUM ( ( 1 - null_frac ) * avg_width ) ) :: BIGINT datawidth FROM pg_stats GROUP BY schemaname, tablename ), t2 AS ( SELECT schemaname, tablename, ( datawidth + 8 - ( CASE WHEN datawidth % 8 = 0 THEN 8 ELSE datawidth % 8 END ) ) -- avg data len + ( 1 - nullfrac ) * 24 + nullfrac * ( nullheader + 8 - ( CASE WHEN nullheader % 8 = 0 THEN 8 ELSE nullheader % 8 END ) ) avgtuplelen FROM t1 ) SELECT C .oid, avgtuplelen FROM t2 T, pg_class C, pg_namespace n WHERE T.schemaname = n.nspname AND C.relname = T.tablename AND C.relnamespace = n.oid AND relpages \u003e 100 ), parti AS ( SELECT parti.inhparent, parti.inhrelid, stat.n_dead_tup, c.relpages, c.reltuples FROM ( SELECT inhparent, inhrelid FROM pg_inherits inh UNION ALL ( SELECT b.inhparent AS grandpa, A.inhrelid me FROM pg_inherits A INNER JOIN pg_inherits b ON A.inhparent = b.inhrelid ) ) AS parti inner join pg_class c on parti.inhrelid = c.oid LEFT JOIN pg_stat_user_tables stat ON parti.inhrelid = stat.relid ) SELECT n.nspname \"tableSchema\", C.relname \"tableName\", SUM ( pg_total_relation_size ( COALESCE ( parti1.inhrelid, C.oid ) ) ) AS \"tableSize\", --表及其子分区、索引大小，包含索引 round( SUM ( pg_total_relation_size ( COALESCE ( parti1.inhrelid, C.oid ) ) ) / ( SELECT SUM ( pg_database_size ( datname ) ) AS dbsize FROM pg_database ), 4 ) AS tblpercent,-- 表占数据文件比例 COALESCE ( MAX ( c.reltuples ), 0 ) + COALESCE ( SUM ( COALESCE ( parti1.reltuples, 0 ) ), 0 ) AS \"tableRows\", CASE WHEN (coalesce(max( bloat.avgtuplelen), 0) = 0 and coalesce(avg( parti1.avgtuplelen), 0) = 0) or MAX ( COALESCE (c.relpages , 0 ) ) + SUM ( COALESCE ( parti1.relpages, 0 )) = 0 THEN 0 ELSE round((1 - CEIL ( (MAX ( COALESCE ( c.reltuples, 0 )) + SUM ( COALESCE ( parti1.reltuples, 0 ))) * (case when max( parti1.avgtuplelen) is not null then AVG( parti1.avgtuplelen) else max ( COALESCE ( bloat.avgtuplelen, 0 ) ) end ) / 8168) / ( MAX ( COALESCE (c.relpages , 0 ) ) + SUM ( COALESCE ( parti1.relpages, 0 )) ))::NUMERIC, 2) END AS bloat_pct, COALESCE ( MAX ( stat.n_dead_tup ), 0 ) + COALESCE ( SUM ( COALESCE ( parti1.n_dead_tup, 0 ) ), 0 ) AS \"deadTup\" --表内死数据行 FROM pg_class C INNER JOIN pg_namespace n ON C.relnamespace = n.oid LEFT JOIN pg_stat_user_tables stat ON C.oid = stat.relid LEFT JOIN (select p.*, b.* from parti p left join bloat as b ON p.inhrelid = b.oid) as parti1 on c.oid = parti1.inhparent LEFT JOIN bloat ON C.oid = bloat.oid WHERE n.nspname NOT IN ( 'pg_catalog', 'information_schema' ) AND n.nspname !~ '^pg_toast' AND C.relkind IN ( 'r', 'p' ) AND C.oid NOT IN ( SELECT inhrelid FROM pg_inherits ) GROUP BY C.relname, n.nspname ORDER BY \"tableSize\" DESC ) as foo group by \"tableSchema\" order by \"schemaSize\" desc\r","date":"2026-02-08","objectID":"/pg_dba/:0:10","tags":["PostgreSQL","資料庫"],"title":"PG_DBA_运维手册","uri":"/pg_dba/"}]